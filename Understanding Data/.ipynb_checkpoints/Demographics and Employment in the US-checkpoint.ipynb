{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographics and Employment in the US\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the wake of the Great Recession of 2009, there has been a good deal of focus on employment statistics, \n",
    "one of the most important metrics policymakers use to gauge the overall strength of the economy. In the United \n",
    "States, the government measures unemployment using the Current Population Survey (CPS), which collects demographic\n",
    "and employment information from a wide range of Americans each month. In this exercise, we will employ the topics reviewed in the lectures as well as a few new techniques using the September 2013 version of this rich, nationally representative dataset (available [online](http://thedataweb.rm.census.gov/ftp/cps_ftp.html)).\n",
    "\n",
    "The observations in the dataset represent people surveyed in the September 2013 CPS who actually completed a survey. While the full dataset has 385 variables, in this exercise we will use a more compact version of the dataset, [CPSData.csv](https://d37djvu3ytnwxt.cloudfront.net/asset-v1:MITx+15.071x_3+1T2016+type@asset+block/CPSData.csv), which has the following variables:\n",
    "\n",
    "* **PeopleInHousehold**: The number of people in the interviewee's household.\n",
    "\n",
    "* **Region**: The census region where the interviewee lives.\n",
    "\n",
    "* **State**: The state where the interviewee lives.\n",
    "\n",
    "* **MetroAreaCode**: A code that identifies the metropolitan area in which the interviewee lives (missing if the interviewee does not live in a metropolitan area). The mapping from codes to names of metropolitan areas is provided in the file [MetroAreaCodes.csv](https://d37djvu3ytnwxt.cloudfront.net/asset-v1:MITx+15.071x_3+1T2016+type@asset+block/MetroAreaCodes.csv).\n",
    "\n",
    "* **Age**: The age, in years, of the interviewee. 80 represents people aged 80-84, and 85 represents people aged 85 and higher.\n",
    "\n",
    "* **Married**: The marriage status of the interviewee.\n",
    "\n",
    "* **Sex**: The sex of the interviewee.\n",
    "\n",
    "* **Education**: The maximum level of education obtained by the interviewee.\n",
    "\n",
    "* **Race**: The race of the interviewee.\n",
    "\n",
    "* **Hispanic**: Whether the interviewee is of Hispanic ethnicity.\n",
    "\n",
    "* **CountryOfBirthCode**: A code identifying the country of birth of the interviewee. The mapping from codes to names of countries is provided in the file [CountryCodes.csv](https://d37djvu3ytnwxt.cloudfront.net/asset-v1:MITx+15.071x_3+1T2016+type@asset+block/CountryCodes.csv).\n",
    "\n",
    "* **Citizenship**: The United States citizenship status of the interviewee.\n",
    "\n",
    "* **EmploymentStatus**: The status of employment of the interviewee.\n",
    "\n",
    "* **Industry**: The industry of employment of the interviewee (only available if they are employed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1 - Loading and Summarizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from CPSData.csv into a data frame called CPS, and view the dataset with the summary() and str() commands.\n",
    "\n",
    "How many interviewees are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131302, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "CPS = pd.read_csv(\"CPSData.csv\")\n",
    "CPS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 131302 observations of 14 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2 - Loading and Summarizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the interviewees with a value reported for the Industry variable, what is the most common industry of employment? Please enter the name exactly how you see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeopleInHousehold</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>MetroAreaCode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Married</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>CountryOfBirthCode</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302</td>\n",
       "      <td>131302</td>\n",
       "      <td>97064.000000</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>105964</td>\n",
       "      <td>131302</td>\n",
       "      <td>105964</td>\n",
       "      <td>131302</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302</td>\n",
       "      <td>105513</td>\n",
       "      <td>66242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen, Native</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Educational and health services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41502</td>\n",
       "      <td>11570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55509</td>\n",
       "      <td>67481</td>\n",
       "      <td>30906</td>\n",
       "      <td>105921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116639</td>\n",
       "      <td>61733</td>\n",
       "      <td>15017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.284276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35074.709264</td>\n",
       "      <td>38.829226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>82.684079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.700173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16551.637597</td>\n",
       "      <td>22.897130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346289</td>\n",
       "      <td>75.476511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21780.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34740.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41860.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79600.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PeopleInHousehold  Region       State  MetroAreaCode            Age  \\\n",
       "count       131302.000000  131302      131302   97064.000000  131302.000000   \n",
       "unique                NaN       4          51            NaN            NaN   \n",
       "top                   NaN   South  California            NaN            NaN   \n",
       "freq                  NaN   41502       11570            NaN            NaN   \n",
       "mean             3.284276     NaN         NaN   35074.709264      38.829226   \n",
       "std              1.700173     NaN         NaN   16551.637597      22.897130   \n",
       "min              1.000000     NaN         NaN   10420.000000       0.000000   \n",
       "25%              2.000000     NaN         NaN   21780.000000      19.000000   \n",
       "50%              3.000000     NaN         NaN   34740.000000      39.000000   \n",
       "75%              4.000000     NaN         NaN   41860.000000      57.000000   \n",
       "max             15.000000     NaN         NaN   79600.000000      85.000000   \n",
       "\n",
       "        Married     Sex    Education    Race       Hispanic  \\\n",
       "count    105964  131302       105964  131302  131302.000000   \n",
       "unique        5       2            8       6            NaN   \n",
       "top     Married  Female  High school   White            NaN   \n",
       "freq      55509   67481        30906  105921            NaN   \n",
       "mean        NaN     NaN          NaN     NaN       0.139328   \n",
       "std         NaN     NaN          NaN     NaN       0.346289   \n",
       "min         NaN     NaN          NaN     NaN       0.000000   \n",
       "25%         NaN     NaN          NaN     NaN       0.000000   \n",
       "50%         NaN     NaN          NaN     NaN       0.000000   \n",
       "75%         NaN     NaN          NaN     NaN       0.000000   \n",
       "max         NaN     NaN          NaN     NaN       1.000000   \n",
       "\n",
       "        CountryOfBirthCode      Citizenship EmploymentStatus  \\\n",
       "count        131302.000000           131302           105513   \n",
       "unique                 NaN                3                5   \n",
       "top                    NaN  Citizen, Native         Employed   \n",
       "freq                   NaN           116639            61733   \n",
       "mean             82.684079              NaN              NaN   \n",
       "std              75.476511              NaN              NaN   \n",
       "min              57.000000              NaN              NaN   \n",
       "25%              57.000000              NaN              NaN   \n",
       "50%              57.000000              NaN              NaN   \n",
       "75%              57.000000              NaN              NaN   \n",
       "max             555.000000              NaN              NaN   \n",
       "\n",
       "                               Industry  \n",
       "count                             66242  \n",
       "unique                               14  \n",
       "top     Educational and health services  \n",
       "freq                              15017  \n",
       "mean                                NaN  \n",
       "std                                 NaN  \n",
       "min                                 NaN  \n",
       "25%                                 NaN  \n",
       "50%                                 NaN  \n",
       "75%                                 NaN  \n",
       "max                                 NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPS.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ```describe``` function above we see the most common Industry is \"Educational and health services\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3 - Loading and Summarizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the homework assignment \"The Analytical Detective\" that you can call the ```sort()``` function on the output of the ```table()``` function to obtain a sorted breakdown of a variable. For instance, ```sort(table(CPS$Region))``` sorts the regions by the number of interviewees from that region.\n",
    "\n",
    "Which state has the fewest interviewees?\n",
    "Which state has the largest number of interviewees?\n",
    "\n",
    "**Note**: In Pyton (using a pandas dataframe) we can use the ```value_counts()``` which gives us an already sorted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California              11570\n",
       "Texas                    7077\n",
       "New York                 5595\n",
       "Florida                  5149\n",
       "Pennsylvania             3930\n",
       "Illinois                 3912\n",
       "Ohio                     3678\n",
       "Maryland                 3200\n",
       "Minnesota                3139\n",
       "Michigan                 3063\n",
       "Virginia                 2953\n",
       "Colorado                 2925\n",
       "Connecticut              2836\n",
       "Georgia                  2807\n",
       "Wisconsin                2686\n",
       "New Hampshire            2662\n",
       "North Carolina           2619\n",
       "New Jersey               2567\n",
       "Iowa                     2528\n",
       "Washington               2366\n",
       "Maine                    2263\n",
       "Delaware                 2214\n",
       "Rhode Island             2209\n",
       "Missouri                 2145\n",
       "Hawaii                   2099\n",
       "Indiana                  2004\n",
       "South Dakota             2000\n",
       "Massachusetts            1987\n",
       "Nebraska                 1949\n",
       "Oregon                   1943\n",
       "Kansas                   1935\n",
       "Vermont                  1890\n",
       "Nevada                   1856\n",
       "Utah                     1842\n",
       "Kentucky                 1841\n",
       "District of Columbia     1791\n",
       "Tennessee                1784\n",
       "South Carolina           1658\n",
       "North Dakota             1645\n",
       "Wyoming                  1624\n",
       "Alaska                   1590\n",
       "Arizona                  1528\n",
       "Oklahoma                 1523\n",
       "Idaho                    1518\n",
       "Louisiana                1450\n",
       "Arkansas                 1421\n",
       "West Virginia            1409\n",
       "Alabama                  1376\n",
       "Mississippi              1230\n",
       "Montana                  1214\n",
       "New Mexico               1102\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPS[\"State\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.4 - Loading and Summarizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of interviewees are citizens of the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Citizen, Native         0.888326\n",
       "Non-Citizen             0.057806\n",
       "Citizen, Naturalized    0.053868\n",
       "Name: Citizenship, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPS[\"Citizenship\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.5 - Loading and Summarizing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPS differentiates between race (with possible values American Indian, Asian, Black, Pacific Islander, White, or Multiracial) and ethnicity. A number of interviewees are of Hispanic ethnicity, as captured by the Hispanic variable. For which races are there at least 250 interviewees in the CPS dataset of Hispanic ethnicity? (Select all that apply.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Race               \n",
       "American Indian   0     1129\n",
       "                  1      304\n",
       "Asian             0     6407\n",
       "                  1      113\n",
       "Black             0    13292\n",
       "                  1      621\n",
       "Multiracial       0     2449\n",
       "                  1      448\n",
       "Pacific Islander  0      541\n",
       "                  1       77\n",
       "White             0    89190\n",
       "                  1    16731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPS[\"Hispanic\"].groupby(CPS[\"Race\"]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1 - Evaluating Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which variables have at least one interviewee with a missing (NA) value? (Select all that apply.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PeopleInHousehold</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>MetroAreaCode</th>\n",
       "      <th>Age</th>\n",
       "      <th>Married</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>CountryOfBirthCode</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302</td>\n",
       "      <td>131302</td>\n",
       "      <td>97064.000000</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>105964</td>\n",
       "      <td>131302</td>\n",
       "      <td>105964</td>\n",
       "      <td>131302</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302.000000</td>\n",
       "      <td>131302</td>\n",
       "      <td>105513</td>\n",
       "      <td>66242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>High school</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen, Native</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Educational and health services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41502</td>\n",
       "      <td>11570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55509</td>\n",
       "      <td>67481</td>\n",
       "      <td>30906</td>\n",
       "      <td>105921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116639</td>\n",
       "      <td>61733</td>\n",
       "      <td>15017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.284276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35074.709264</td>\n",
       "      <td>38.829226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>82.684079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.700173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16551.637597</td>\n",
       "      <td>22.897130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346289</td>\n",
       "      <td>75.476511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21780.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34740.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41860.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79600.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PeopleInHousehold  Region       State  MetroAreaCode            Age  \\\n",
       "count       131302.000000  131302      131302   97064.000000  131302.000000   \n",
       "unique                NaN       4          51            NaN            NaN   \n",
       "top                   NaN   South  California            NaN            NaN   \n",
       "freq                  NaN   41502       11570            NaN            NaN   \n",
       "mean             3.284276     NaN         NaN   35074.709264      38.829226   \n",
       "std              1.700173     NaN         NaN   16551.637597      22.897130   \n",
       "min              1.000000     NaN         NaN   10420.000000       0.000000   \n",
       "25%              2.000000     NaN         NaN   21780.000000      19.000000   \n",
       "50%              3.000000     NaN         NaN   34740.000000      39.000000   \n",
       "75%              4.000000     NaN         NaN   41860.000000      57.000000   \n",
       "max             15.000000     NaN         NaN   79600.000000      85.000000   \n",
       "\n",
       "        Married     Sex    Education    Race       Hispanic  \\\n",
       "count    105964  131302       105964  131302  131302.000000   \n",
       "unique        5       2            8       6            NaN   \n",
       "top     Married  Female  High school   White            NaN   \n",
       "freq      55509   67481        30906  105921            NaN   \n",
       "mean        NaN     NaN          NaN     NaN       0.139328   \n",
       "std         NaN     NaN          NaN     NaN       0.346289   \n",
       "min         NaN     NaN          NaN     NaN       0.000000   \n",
       "25%         NaN     NaN          NaN     NaN       0.000000   \n",
       "50%         NaN     NaN          NaN     NaN       0.000000   \n",
       "75%         NaN     NaN          NaN     NaN       0.000000   \n",
       "max         NaN     NaN          NaN     NaN       1.000000   \n",
       "\n",
       "        CountryOfBirthCode      Citizenship EmploymentStatus  \\\n",
       "count        131302.000000           131302           105513   \n",
       "unique                 NaN                3                5   \n",
       "top                    NaN  Citizen, Native         Employed   \n",
       "freq                   NaN           116639            61733   \n",
       "mean             82.684079              NaN              NaN   \n",
       "std              75.476511              NaN              NaN   \n",
       "min              57.000000              NaN              NaN   \n",
       "25%              57.000000              NaN              NaN   \n",
       "50%              57.000000              NaN              NaN   \n",
       "75%              57.000000              NaN              NaN   \n",
       "max             555.000000              NaN              NaN   \n",
       "\n",
       "                               Industry  \n",
       "count                             66242  \n",
       "unique                               14  \n",
       "top     Educational and health services  \n",
       "freq                              15017  \n",
       "mean                                NaN  \n",
       "std                                 NaN  \n",
       "min                                 NaN  \n",
       "25%                                 NaN  \n",
       "50%                                 NaN  \n",
       "75%                                 NaN  \n",
       "max                                 NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPS.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2 - Evaluating Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when evaluating a new dataset, we try to identify if there is a pattern in the missing values in the dataset. We will try to determine if there is a pattern in the missing values of the Married variable. The function `is.na(CPS$Married)` returns a vector of TRUE/FALSE values for whether the Married variable is missing. We can see the breakdown of whether Married is missing based on the reported value of the Region variable with the function `table(CPS$Region, is.na(CPS$Married))`. Which is the most accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Region          \n",
       " Midwest    False    24609\n",
       "            True      6075\n",
       " Northeast  False    21432\n",
       "            True      4507\n",
       " South      False    33535\n",
       "            True      7967\n",
       " West       False    26388\n",
       "            True      6789\n",
       " dtype: int64, Sex          \n",
       " Female  False    55264\n",
       "         True     12217\n",
       " Male    False    50700\n",
       "         True     13121\n",
       " dtype: int64, Age       \n",
       " 0    True     1283\n",
       " 1    True     1559\n",
       " 2    True     1574\n",
       " 3    True     1693\n",
       " 4    True     1695\n",
       " 5    True     1795\n",
       " 6    True     1721\n",
       " 7    True     1681\n",
       " 8    True     1729\n",
       " 9    True     1748\n",
       " 10   True     1750\n",
       " 11   True     1721\n",
       " 12   True     1797\n",
       " 13   True     1802\n",
       " 14   True     1790\n",
       " 15   False    1795\n",
       " 16   False    1751\n",
       " 17   False    1764\n",
       " 18   False    1596\n",
       " 19   False    1517\n",
       " 20   False    1398\n",
       " 21   False    1525\n",
       " 22   False    1536\n",
       " 23   False    1638\n",
       " 24   False    1627\n",
       " 25   False    1604\n",
       " 26   False    1643\n",
       " 27   False    1657\n",
       " 28   False    1736\n",
       " 29   False    1645\n",
       "               ... \n",
       " 52   False    1935\n",
       " 53   False    1994\n",
       " 54   False    1912\n",
       " 55   False    1895\n",
       " 56   False    1935\n",
       " 57   False    1827\n",
       " 58   False    1874\n",
       " 59   False    1758\n",
       " 60   False    1746\n",
       " 61   False    1735\n",
       " 62   False    1595\n",
       " 63   False    1596\n",
       " 64   False    1519\n",
       " 65   False    1569\n",
       " 66   False    1577\n",
       " 67   False    1227\n",
       " 68   False    1130\n",
       " 69   False    1062\n",
       " 70   False    1195\n",
       " 71   False    1031\n",
       " 72   False     941\n",
       " 73   False     896\n",
       " 74   False     842\n",
       " 75   False     763\n",
       " 76   False     729\n",
       " 77   False     698\n",
       " 78   False     659\n",
       " 79   False     661\n",
       " 80   False    2664\n",
       " 85   False    2446\n",
       " dtype: int64, Citizenship                \n",
       " Citizen, Native       False    91956\n",
       "                       True     24683\n",
       " Citizen, Naturalized  False     6910\n",
       "                       True       163\n",
       " Non-Citizen           False     7098\n",
       "                       True       492\n",
       " dtype: int64]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pd.isnull(CPS[\"Married\"]).groupby(CPS[\"Region\"]).value_counts(),\n",
    " pd.isnull(CPS[\"Married\"]).groupby(CPS[\"Sex\"]).value_counts(),\n",
    " pd.isnull(CPS[\"Married\"]).groupby(CPS[\"Age\"]).value_counts(),\n",
    " pd.isnull(CPS[\"Married\"]).groupby(CPS[\"Citizenship\"]).value_counts()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: The Married variable being missing is related to Age. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3 - Evaluating Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the variable descriptions, MetroAreaCode is missing if an interviewee does not live in a metropolitan area. Using the same technique as in the previous question, answer the following questions about people who live in non-metropolitan areas.\n",
    "\n",
    "How many states had all interviewees living in a non-metropolitan area (aka they have a missing MetroAreaCode value)? For this question, treat the District of Columbia as a state (even though it is not technically a state).\n",
    "\n",
    "How many states had all interviewees living in a metropolitan area? Again, treat the District of Columbia as a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                      \n",
       "Alabama               False     1020\n",
       "                      True       356\n",
       "Alaska                True      1590\n",
       "Arizona               False     1327\n",
       "                      True       201\n",
       "Arkansas              False      724\n",
       "                      True       697\n",
       "California            False    11333\n",
       "                      True       237\n",
       "Colorado              False     2545\n",
       "                      True       380\n",
       "Connecticut           False     2593\n",
       "                      True       243\n",
       "Delaware              False     1696\n",
       "                      True       518\n",
       "District of Columbia  False     1791\n",
       "Florida               False     4947\n",
       "                      True       202\n",
       "Georgia               False     2250\n",
       "                      True       557\n",
       "Hawaii                False     1576\n",
       "                      True       523\n",
       "Idaho                 False      761\n",
       "                      True       757\n",
       "Illinois              False     3473\n",
       "                      True       439\n",
       "Indiana               False     1420\n",
       "                      True       584\n",
       "Iowa                  False     1297\n",
       "                      True      1231\n",
       "                               ...  \n",
       "Ohio                  False     2754\n",
       "                      True       924\n",
       "Oklahoma              False     1024\n",
       "                      True       499\n",
       "Oregon                False     1519\n",
       "                      True       424\n",
       "Pennsylvania          False     3245\n",
       "                      True       685\n",
       "Rhode Island          False     2209\n",
       "South Carolina        False     1139\n",
       "                      True       519\n",
       "South Dakota          True      1405\n",
       "                      False      595\n",
       "Tennessee             False     1149\n",
       "                      True       635\n",
       "Texas                 False     6060\n",
       "                      True      1017\n",
       "Utah                  False     1455\n",
       "                      True       387\n",
       "Vermont               True      1233\n",
       "                      False      657\n",
       "Virginia              False     2367\n",
       "                      True       586\n",
       "Washington            False     1937\n",
       "                      True       429\n",
       "West Virginia         True      1065\n",
       "                      False      344\n",
       "Wisconsin             False     1882\n",
       "                      True       804\n",
       "Wyoming               True      1624\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(CPS[\"MetroAreaCode\"]).groupby(CPS[\"State\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
